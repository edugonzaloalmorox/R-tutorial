---
title: "Data management through R"
author: "Newcaste University Business School"
date: "4/11/2016"
output:
  slidy_presentation:
    font_adjustment: 2
    footer: Intro to R - Edu Gonzalo Almorox 4/11/2016
    fig_width: 10
    fig_height: 8
    fig_caption: true
subtitle: Edu Gonzalo Almorox
---

## Introduction... R in a nutshell 

- What is [R](https://www.r-project.org)?   _programming language_, _environment_, _software_...

    - Object programming 
    - Open source and free
    - Compatibility with other languages i.e., Phyton, Javascript
    - Important learning curve 
    - Documentation far from perfect but getting into shape.
      
    
- What is [RStudio](https://www.rstudio.com)? Integrated Development Environment that makes R programming more user friendly. 

- What can you do with R?

    - Data analysis
    - Data manipulation
    - Data visualisation
    - Dynamic documents 
    - Techniques 
      - .... possibly more things that I don´t know

## Is R a good investment?



![_Scholarly articles in Google Scholar_](http://i0.wp.com/r4stats.com/wp-content/uploads/2012/04/Fig_2d_ScholarlyImpact.png)

![_Scholary articles in Google Scholar with no SPSS and SAS_](http://i0.wp.com/r4stats.com/wp-content/uploads/2012/04/Fig_2e_ScholarlyImpactSubset.png)

![_Analytic Jobs_](http://i0.wp.com/datasciencepopularity.com/wp-content/uploads/2014/03/fig_1a_indeedjobs2014ge2501.png)

Source: "The popularity of Data Analysis software (Muenchen (2016) "(www.r4stats.com)



## How do we structure a data analysis project?

- Steps in a data analysis project 



![](http://r4ds.had.co.nz/diagrams/data-science.png)

Source: _R for Data Science_ (Wickham and Grolemund (2016))


## Let´s get our head around...

**Step 1: Create a project**

Project enable a better organizaation of the files and keeps a better control of the workflow (e.g. scripts, data, final documents, etc...). Projects also improve the efficiency. 

- Generate a project 

    - `Project - New Project - New Directory -  Empty project - (select directory...)`
    - Create different folders containing different types (data, code, figures, documents...)   

- _Optional_ (although highly recomended): Create a control version of the project 

    - It enhances reproducibility and collaboration
    - Keeps record and reduces errors 
    - Limits software dependency
    

**Step 2: Resources**

- In case of doubt there are different ways to proceed: 

     + Specialised websites - e.g. [stackoverflow.com](http://stackoverflow.com/questions/tagged/r)
     + [R Mailing lists](https://www.r-project.org/mail.html)
     + `help`, `help.search()`, `??(name package/name function)`


## Data structures 

- In R every element is regarded as an object. Objects are data structures that group data according to specific attributes. Most general data structures are organised by two elements

    - Dimensionality 
    - Type of the contents (homogeneous, heterogeneous)
    
      1. **`numeric or character`**: single number of letter
      
      2. **`Vector`**: 1 dimension, homogeneous objects.
      
      3. **`List`**: 1 dimension, heterogenous objects - (different objects grouped together)
      
      3. **`Matrix`**: more than 1 dimension, homogenous objects 
      
      4. **`Data frame`**: more than 1 dimension, heterogenous objects. 
      
  

## Data structures: examples 


* This is a `vector`
```{r, echo = FALSE, include = TRUE}

v =c(1,2,3,4)
v
```

* This is a `list`
```{r, echo = FALSE, include = TRUE}

l = list(c(1:5), c(1:2))
l
```

This is a `data.frame`
```{r, echo = FALSE, include = TRUE}
df = data.frame(numbers = c(1,2), letters = c("a", "b") )
df
```

* Data.frames are the most common data structure for gathering information.

    - **Variables**: Collect different arguments associated with the information to be analysed - diffrent formats (numbers, strings, factors, dates, ...)
    - **Observations**: Units of analysis (individuals, firms, etc...) - e.g. the rows of your dataset.
    

## Inputting information 

-  There are two possible ways to input information: 

     - **Manually**
     
     - **Import from somewhere**

- The majority of the analyses import data 

    - Data are delivered in different formats
    - Important to understand how information is structured 
            
**Step 1: Get started**

- The first commands consist of the following instructions: 

```{r, echo = TRUE, eval = FALSE}

# working directory
setwd("/Users/Personas/My Cloud/PhD _october_2016/teaching/R tutorial") 

#install.packages() # for installing packages 
#library("") # for loading libraries

```

**Step 2: Load your data**

* There are a number of packages and libraries that allow for this. Their use depends on the type of data that you want to load. The most typical functions are.

       - `read.csv()` (`base`)
       - `read.dta()` (`foreign`)
       - `import()` (`rio`)
       - `read_csv`, `read_xlsx`... (`readr`)
       
       
## Load your data: `read.csv`

Very used function for loading `.csv` files

```{r, echo = TRUE, include = TRUE, message = FALSE, warning = FALSE}

# load 'df'
  df = read.csv("data_intro_r.csv", sep = ",", header = TRUE) 

#get the first observations 
  head(df)

```


## Load your data: `read.dta`

There are other packages that allow to import information in other formats. 

```{r, echo = TRUE, include = TRUE, message = FALSE, warning = FALSE}

library(foreign)

# load 'df'
  df = read.csv("data_intro_r.csv", sep = ",", header = TRUE) 

#get the first observations 
  head(df)

```


## Load your data: `import()`

It is more flexible than `read.csv` or  `read_dta` since it requires less arguments. 

```{r, echo = TRUE, include = TRUE, message = FALSE, warning = FALSE}

# load 'df'
  library(rio)
  df = import("data_intro_r.csv") 

#get the first observations 
  head(df)

```

- Package [rio](https://cran.r-project.org/web/packages/rio/index.html) can import data in several formats. 

- These examples consider cases where **data are hosted locally** (e.g. in the computer). However, it is possible to get information directly from websites.

    - Depending on the type of data the process can be more or less complex.


## Export your data 

How do we **save** our work after carrying out analysis? 

* Two main options based on the former packages. 

       1.  **`write.csv()`**
       2.  **`export()`**

```{r, echo = TRUE, include = TRUE, message = FALSE, warning = FALSE}

# libraries 
  library(rio)
  library(dplyr)
  
# load df
  df = import("data_intro_r.csv") 

# do some analysis - e.x. subset data 
  my_sub_data = df %>% select(location.id, date)  # select location and date 
  
# get the first observations - check it is the result we want.
  head(my_sub_data)

# save the output 
  
      # write csv version
          write.csv(my_sub_data, "new_data.csv", row.names = FALSE)
      # export version
          export(my_sub_data, "new_data.csv")

```
    


## Exploring the data 

Once we have loaded the data, we can run some functions to check structure and characteristics of the `data.frame`

- What do we mean by "exploring the data?"

    - What type of variables do we have?
    - How many (missing) observations?
    - How many duplicates? 
    - ....

- `str() allows to exlopre the structure of the `data.frame` and the type of variables are in it.

```{r, echo = TRUE, include = TRUE, message = FALSE, warning = FALSE}


str(df)

```

 - Also we can get **summaries** of the variables that composed that `data.frame`
  
```{r, echo = TRUE, include = TRUE, message = FALSE, warning = FALSE}


summary(df)

```

## Types of data: factors and logical 

There are different types of variables depending on the characteristics they represent.

    
- **factors**: They represent categories. They act as dummy variables and can be either numeric or strings (e.g. group of characters). `factor()` can convert a variable into a factor. `class()` can be used to check the type of variable. 


```{r, echo = TRUE, include = TRUE}

location_factor = factor(df$location.id)
class(location_factor)
```

- **logical**: it can take just tow values `TRUE` or `FALSE`. Used for logical questions (e.g. is my variable a factor?)

```{r, echo = TRUE, include = TRUE, message = TRUE}

is.factor(df$location_factor)
```

- Are the first 5 observations of `jsa.fem()` 55?

```{r, echo = TRUE, include = TRUE, message = TRUE}

head(df$jsa.fem == 55)
```

## Data manipulation: old times 

Normally we have to transform "_clean_" the raw information in order to meet other purposes. These transformations may entail adding (dropping) variables, adding (dropping) rows, select certain variables (rows)...

- **Indexing(`$`)**: `mydata$myvariable`

```{r, echo = TRUE, include = TRUE, message = TRUE}

indexed_var = df$jsa.fem
head(indexed_var)
```

- **Using []**: `mydata[nrow, ncolum]`

```{r, echo = TRUE, include = TRUE, message = TRUE}

# Get the 5 rows of 'region' and 'date'
first_regions= df[1:5, c(2,3)]
first_regions
```

- **Subset (`subset()`)**: `new.data = subset(old.data, cond_var1, condvar2)`



```{r, echo = TRUE, include = TRUE, message = TRUE}

# Select location jsa.fem equal to 40.

jsa.40 = subset(df, jsa.fem == 40)
head(jsa.40)
```

## Data manipulation now: _the "yr" family_

"_Tidy datasets provide a standarized way to link the structure of a dataset (its physical layout) with its semantics (its meaning)_" (Hadley Wickham^[Wickham, Hadley (2014) "Tidy data". _Journal of Statistical Software Volume VV Issue II_])

- When working wih data there are several things to have in mind 

    - What do you want to do with the data?
    - What tasks do I need for obtaining my purposes?
    - How I execute them in a program?

- `...yr()` packages are helpful resources to address these questions. They include:

    - **`dplyr()`**
    - **`tidyr()`**
   

## `dplyr()`

- It is based on the _split - apply - combine_ concept so you can carry out various operations quite efficiently. 

- It includes several useful functions: 

    - `select()` and `slice()`: cast some variables
    - `filter()`: filter certain rows 
    - `arrange()`: sort variables
    - `summarise()`: get summaries according to certain conditions
    - `mutate()`: add variables 
    - `distinct()`: get unique variables
    - `group_by()`: grouped operations

- Dplyr enables **pipes (%>%)** - very useful when there are multiple operations.

 **Example 1**: _Select those regions and dates where job seekers allowance is 40_

```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example

jsa.40 = subset(df, jsa.fem == 40) # step 1 - filter rows

final_jsa = jsa.40[, c(2,3)] # step 2 - select variables of interest 

head(final_jsa, 7) # show results 
  
```

**Example 1 bis - Introducing the syntax of dplyr throughout pipes** 
    
     
```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example with dplyr and pipes 

library(dplyr)
final_jsa_piped = df %>% filter(jsa.fem == 40) %>%  select(location.region, date)

head(final_jsa_piped,7)


  
```
    
    

## `dplyr()` in detail

**Example 2 - Multiple operations**: _Select those firms that are based in the North East, that have a date and where the job seekers allowance is below the average._

```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example 2

library(dplyr)
example2= df %>% filter(jsa.fem < mean(jsa.fem), !is.na(date), location.region == "North East") %>% 
     select(location.id)

head(example2, 5)

```

`!is.na()` is a logical operator. There are other useful ones to consider

```{r, eval = FALSE, echo = TRUE}
<   Less than                    !=      Not equal to
>   Greater than                 %in%    Group membership
==  Equal to                     is.na   is NA
<=  Less than or equal to        !is.na  is not NA
>=  Greater than or equal to     &,|,!   Boolean operators

```

**Example 3 - Add variables**: _Create a variable that represents the mean the minimum and the maximum proportion of job seekers in the country. Sort observations in a descending order of number of job seekers._

```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example 3 
example3= df %>% mutate(jsa_mean = mean(jsa.fem), 
                        jsa_min = min(jsa.fem),
                        jsa_max = max(jsa.fem)) %>%  arrange(desc(jsa.fem))
                                             

head(example3, 5)

```

**Example 4 - Grouped operations**: _Create a variable that represents the mean the minimum and the maximum proportion of job seekers of each region._


```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example 4
example4= df %>% group_by(location.region) %>%
  mutate(jsa_mean = mean(jsa.fem), 
                        jsa_min = min(jsa.fem),
                        jsa_max = max(jsa.fem))

head(example4, 5)

```


**Example 5 - Get unique observations**: _Obtain a single observation of each firm and remove dates_


```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example 5
example5= df  %>% distinct(location.id, .keep_all =TRUE) %>% select(-date)

head(example5, 5)

```

**Example 6 - Rename variables**: _Rename "location.id" and "location.region" by "firm" and "region"_


```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example 6
example6= df  %>% dplyr:: rename(firm = location.id, region = location.region)

head(example6, 5)

```

## `tidyr`

- This package is very useful when you want to change "reshape" the structure of your dataset.

      - `gather()`: from wide to long.
      - `spread()`: fromo long to wide.

It is important to consider three elements: data object, key variable and value. 

- **Example 7 - Transform the structure of the dataset**: From wide to long using `credits.csv` data.

```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example 7

library(rio)
library(tidyr)

credits = import("credits.csv")

example7 = gather(credits, date, people_credits, FEB10:FEB16, factor_key = TRUE) %>% arrange(OA)

head(example7, 5)

```

- **Example 7 bis - Transform the structure of the dataset**: From long to wide

```{r, echo = TRUE, include = TRUE, message = TRUE}

# Example 7 -bis

library(rio)
library(tidyr)

credits = import("credits.csv")

example7.1 = spread(example7, date, people_credits) %>% arrange(OA)

head(example7.1, 5)

```

## Graphics: `ggplot2`

- Most of the visualisation tools in R rely to more or less extent on `ggplot2`. `ggplot2` is based on the grammar of graphics, a system for describing and building the graphs.

- When illustrating data you need to determine the purpose of your plots:

    - Exploration
    - Communication

- We consider `df` as the data frame. 

**Example 8**: _Represent a  histogram of the job seekers allowance._ 
```{r, echo = TRUE, include = TRUE, message = FALSE}

# Example 8 

library(ggplot2)

example8 = ggplot(df) + 
  geom_histogram(mapping = aes(jsa.fem))
example8

```

**Example 9**: _Represent the number of job seekers per region._ 
```{r, echo = TRUE, include = TRUE, message = FALSE}

# Example 9 

# option A
library(ggplot2)

df$location.region = as.factor(df$location.region)

example9.a = ggplot(df) + 
  geom_histogram(mapping = aes(x= jsa.fem, fill = location.region))
example9.a


# option B
example9.b = ggplot(df) + 
  geom_histogram(mapping = aes(x= jsa.fem, fill = location.region), position = "dodge")
example9.b

#option C 

example9.c = ggplot(df) + 
  geom_histogram(mapping = aes(x= jsa.fem)) + facet_grid(. ~ location.region, scales = "free", space = "free")
example9.c

```


## Dynamic documents: R Markdown

- **R Markdown**: Unified framework that combines code, results and prose. 
- Why integrating code, results and prose?

      - Communication
      - Collaboration
      - New environment and way of working with data


```{r, eval = FALSE, echo = TRUE}

---
title: "Introduction to R"
date: "4/11/2016"
output: html_document
---
  {r, echo = TRUE, include = TRUE, message = FALSE}

# Example 9 

# option A
library(ggplot2)

df$location.region = as.factor(df$location.region)

example9.a = ggplot(df) + 
  geom_histogram(mapping = aes(x= jsa.fem, fill = location.region))
example9.a
    
    
  This is an example of markdown that uses ggplot and blahblah blah. 
  
```

- There are three important issues to consider

    - **YAML** header that is surronded by `---
    - **Chunks** is where the R code is allocated 
    - Text is structured by `# headings`
    
- Results can be delivered in different formats: pdf (latex), html (for website documents) or word. 

- `rmarkdown()` and `knitr()`

## Example of Rmarkdown: present results from a model 

- We need `stargazer()` for translating the results of a model into a table.

- Using `data_model`

**Step 1**: Run the regressions `lm` 

```{r, echo = TRUE, include = TRUE, message = FALSE, results = 'asis'}

data_model = read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv")

      mod1 <- lm(mpg ~  cyl+ hp, data=data_model)
      
      mod2 <- lm(mpg ~ cyl+ hp + drat, data=data_model)
      
      mod3 <- lm(mpg ~ + cyl+ hp+ wt+ qsec + carb, data=data_model)
```   


**Step 2**: Present the table with results
```{r, results = 'asis', message = FALSE, echo = TRUE}

library(stargazer)
      
      # Results of model comparison
      stargazer(mod1, mod2, mod3, header=FALSE, type='html')

```


**Step 2 bis**: Edit the table of results 

```{r, results = 'asis', message = FALSE, echo = TRUE}

library(stargazer)
      
      # Results of model comparison
      stargazer(mod1, mod2, mod3, header=FALSE, type='html',
                title  = "Regression: Nobel price results", 
                column.labels = c("mod1", "mod2", "mod3"),
                notes.label = "We have done this fancy IV method")

```


## Final notes 

- R is a good alternative if you are thinking about carrying out projects that entail a decent amount of data analysis.

- There are more advanced topics 

    - Spatial analysis
    - Dynamic plots 
    - Text mining
    - Network analysis

- There are plenty of resources - things are getting incredibly better and really fast.

        



